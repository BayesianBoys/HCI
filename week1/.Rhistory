mutate(name = as_factor(name))
# likelihood and posterior the same bc. flat prior
g_reshape %>%
ggplot(aes(x = p_grid, ymin = 0, ymax = value, fill = name)) +
geom_ribbon() +
scale_fill_manual(values = wes_palette("Cavalcanti1")) +
#scale_y_continuous(NULL, breaks = NULL) +
theme(legend.position = "none") +
facet_wrap(~name)
# better than chance (approaches 0.5 as n --> infinity).
g %>%
filter(p_grid < 0.5) %>%
summarize(above = sum(posterior))
library(pacman)
p_load(tidyverse, rethinking, wesanderson, bayestestR)
# basic data tibble
d <- tibble(
Correct=c(3,2,160,66),
Questions=c(6,2,198,132),
Teacher=c("RF","KT","DC","MW"))
# number of points to seq along.
n <- 1000
# the grid for Riccardo.
g <- tibble(p_grid = seq(0, 1, length.out = n),
prior = 1) %>%
mutate(likelihood = dbinom(x = d$Correct[d$Teacher == "RF"],
size = d$Questions[d$Teacher == "RF"],
p_grid)) %>%
mutate(posterior = (prior * likelihood) / (sum(prior * likelihood)))
# reshaping and plotting
g_reshape <- g %>%
mutate(prior = prior/n,
likelihood = likelihood / sum(likelihood)) %>%
pivot_longer(cols = !p_grid) %>%
mutate(name = as_factor(name))
# likelihood and posterior the same bc. flat prior
g_reshape %>%
ggplot(aes(x = p_grid, ymin = 0, ymax = value, fill = name)) +
geom_ribbon() +
scale_fill_manual(values = wes_palette("Cavalcanti1")) +
#scale_y_continuous(NULL, breaks = NULL) +
theme(legend.position = "none") +
facet_wrap(~name)
# better than chance (approaches 0.5 as n --> infinity).
g %>%
filter(p_grid < 0.5) %>%
summarize(above = sum(posterior))
# reshaping and plotting
g %>%
mutate(prior = prior/n,
likelihood = likelihood / sum(likelihood)) %>%
pivot_longer(cols = !p_grid) %>%
mutate(name = as_factor(name)) %>%
ggplot(aes(x = p_grid, ymin = 0, ymax = value, fill = name)) +
geom_ribbon() +
scale_fill_manual(values = wes_palette("Cavalcanti1")) +
#scale_y_continuous(NULL, breaks = NULL) +
theme(legend.position = "none") +
facet_wrap(~name)
library(pacman)
p_load(tidyverse, rethinking, wesanderson, bayestestR)
# basic data tibble
d <- tibble(
Correct=c(3,2,160,66),
Questions=c(6,2,198,132),
Teacher=c("RF","KT","DC","MW"))
# number of points to seq along.
n <- 1000
# the grid for Riccardo.
g <- tibble(p_grid = seq(0, 1, length.out = n),
prior = 1) %>%
mutate(likelihood = dbinom(x = d$Correct[d$Teacher == "RF"],
size = d$Questions[d$Teacher == "RF"],
p_grid)) %>%
mutate(posterior = (prior * likelihood) / (sum(prior * likelihood)))
# reshaping and plotting
g %>%
mutate(prior = prior/n,
likelihood = likelihood / sum(likelihood)) %>%
pivot_longer(cols = !p_grid) %>%
mutate(name = as_factor(name)) %>%
ggplot(aes(x = p_grid, ymin = 0, ymax = value, fill = name)) +
geom_ribbon() +
scale_fill_manual(values = wes_palette("Cavalcanti1")) +
theme(legend.position = "none") +
facet_wrap(~name)
# better than chance (approaches 0.5 as n --> infinity).
g %>%
filter(p_grid < 0.5) %>%
summarize(above = sum(posterior))
# quadratic
q <- quap(
alist(
c ~ dbinom(total, p),
p ~ dunif(0, 1)
),
data = list(
c = d$Correct[d$Teacher == "RF"],
total = d$Questions[d$Teacher == "RF"]
)
)
# check values
precis(q)
# plot stuff
n_grid <- 1000
# basic data frame
data <- tibble(p_grid = seq(from = 0,
to = 1,
length.out = n_grid),
prior = 1,
c = 3,
n = 6,
m = 0.5,
sd = 0.2) %>%
mutate(likelihood = dbinom(3, 6, p_grid),
grid_post = prior * likelihood / sum(prior * likelihood),
quad_post = dnorm(p_grid, m, sd) / sum(dnorm(p_grid, m, sd)))
# data wrangling & plotting
data %>%
pivot_longer(cols = grid_post:quad_post) %>%
mutate(name = as_factor(name)) %>%
ggplot(aes(x = p_grid, y = value, color = name)) +
geom_line()
# funcgion for computing posterior with grid.
grid_posterior <- function(data, n_grid, prior){
#empty placeholders
grid_teacher = tibble()
#main loop
for(i in data$Teacher){
g <- tibble(p_grid = seq(0, 1, length.out = n_grid),
prior = prior) %>%
mutate(likelihood = dbinom(x = data$Correct[d$Teacher == i],
size = data$Questions[d$Teacher == i],
p_grid)) %>%
mutate(posterior = (prior * likelihood) / (sum(prior * likelihood)),
Teacher = i)
grid_teacher = bind_rows(grid_teacher, g)
}
return(grid_teacher)
}
# funcgion for computing posterior with grid.
grid_posterior <- function(data, n_grid, prior){
#empty placeholders
grid_teacher = tibble()
#main loop
for(i in data$Teacher){
g <- tibble(p_grid = seq(0, 1, length.out = n_grid),
prior = prior) %>%
mutate(likelihood = dbinom(x = data$Correct[data$Teacher == i],
size = data$Questions[data$Teacher == i],
p_grid)) %>%
mutate(posterior = (prior * likelihood) / (sum(prior * likelihood)),
Teacher = i)
grid_teacher = bind_rows(grid_teacher, g)
}
return(grid_teacher)
}
# uniform prior
n_grid = 10000
prior = 1
res_uniform <- grid_posterior(d, n_grid, prior)
# uniform prior
n_grid = 10000
prior = 1
g_uniform <- grid_posterior(d, n_grid, prior)
# plotting
library(RColorBrewer)
(
p1 <- g_uniform %>%
ggplot(aes(x = p_grid, ymin = 0, ymax = posterior, fill = Teacher)) +
geom_ribbon(alpha = 0.5) +
geom_line(aes(x = p_grid, y = posterior)) +
geom_line(aes(x = p_grid, y = prior/n_grid), color = "red") +
scale_fill_brewer(palette = "Dark2") +
labs(title = "Teacher knowledge with flat prior")
)
# sampling from posterior
s_uniform <- g_uniform %>%
group_by(Teacher) %>%
slice_sample(n = 1000,
weight_by = posterior,
replace = T)
# taking them out.
s_unif %>% group_by(Teacher) %>% summarize(
l_95 = bayestestR::hdi(p_grid,.width = .95)[[2]],
u_95 = bayestestR::hdi(p_grid,.width = .95)[[3]],
mean = mean(p_grid, na.rm = T),
sd = sd(p_grid, na.rm = T) #should this not be sd?
)
# taking them out.
s_uniform %>% group_by(Teacher) %>% summarize(
l_95 = bayestestR::hdi(p_grid,.width = .95)[[2]],
u_95 = bayestestR::hdi(p_grid,.width = .95)[[3]],
mean = mean(p_grid, na.rm = T),
sd = sd(p_grid, na.rm = T) #should this not be sd?
)
# normal prior
n_grid = 10000
p_grid = seq(from = 0, to = 1, length.out = n_grid)
# normal prior
n_grid = 10000
p_grid = seq(from = 0, to = 1, length.out = n_grid)
prior = dnorm(p_grid, mean = 0.8, sd = 0.2)
res_normal <- grid_posterior(d, n_grid, prior)
# plotting
(
p2 <- res_normal %>%
ggplot(aes(x = p_grid, ymin = 0, ymax = posterior, fill = Teacher)) +
geom_ribbon(alpha = 0.5) +
geom_line(aes(x = p_grid, y = posterior)) +
geom_line(aes(x = p_grid, y = prior/n_grid), color = "red") +
scale_fill_brewer(palette = "Dark2") +
labs(title = "Teacher knowledge with appreciative prior")
)
library(cowplot)
plot_grid(p1, p2) #could remove legend of one of them..
# sampling from posterior
samples_normal <- res_normal %>%
group_by(Teacher) %>%
slice_sample(n = 1000,
weight_by = posterior,
replace = T)
# sampling from posterior
s_normal <- res_normal %>%
group_by(Teacher) %>%
slice_sample(n = 1000,
weight_by = posterior,
replace = T)
# taking them out.
s_normal %>% group_by(Teacher) %>% summarize(
l_95 = bayestestR::hdi(p_grid,.width = .95)[[2]],
u_95 = bayestestR::hdi(p_grid,.width = .95)[[3]],
mean = mean(p_grid, na.rm = T),
sd = sd(p_grid, na.rm = T)
)
s_uniform %>% group_by(Teacher) %>% summarize(
l_95 = bayestestR::hdi(p_grid,.width = .95)[[2]],
u_95 = bayestestR::hdi(p_grid,.width = .95)[[3]],
mean = mean(p_grid, na.rm = T),
sd = sd(p_grid, na.rm = T)
)
# new data
d2 <- tibble(
Correct = c(9, 8, 148, 34),
Questions = c(10, 12, 172, 65),
Teacher = c("RF", "KT", "DC", "MW")
)
# using the normal.
grid_update <- function(d_old, d_new, n_grid){
# empty placeholder
grid_teacher2 <- tibble()
# main loop
for(i in d_new$Teacher){
g <- d_old %>%
filter(Teacher == {{i}}) %>%
mutate(prior = posterior,
likelihood = dbinom(x = d_new$Correct[d_new$Teacher == i],
size = d_new$Questions[d_new$Teacher == i],
p_grid)) %>%
mutate(posterior = (prior * likelihood) / (sum(prior * likelihood)))
grid_teacher2 <- bind_rows(grid_teacher2, g)
}
return(grid_teacher2)
}
# flat prior & update
n_grid <- 10000
res_uniform2 <- grid_update(res_uniform, d2, n_grid)
View(res_uniform)
View(d2)
library(pacman)
p_load(tidyverse, rethinking, wesanderson, bayestestR)
# basic data tibble
d <- tibble(
Correct=c(3,2,160,66),
Questions=c(6,2,198,132),
Teacher=c("RF","KT","DC","MW"))
# number of points to seq along.
n <- 1000
d$Correct[d$Teacher == "RF"]
d %>%
filter(Teacher == "RF") %>%
summarize(Correct)
g <- tibble(p_grid = seq(0, 1, length.out = n),
prior = 1) %>%
mutate(likelihood = dbinom(
x = d %>% filter(Teacher == "RF") %>% summarize(Correct),
size = d %>% filter(Teacher == "RF") %>% summarize(Questions),
p_grid
)) %>%
glimpse()
# the grid for Riccardo.
g <- tibble(p_grid = seq(0, 1, length.out = n),
prior = 1) %>%
mutate(likelihood = dbinom(x = d$Correct[d$Teacher == "RF"],
size = d$Questions[d$Teacher == "RF"],
p_grid)) %>%
mutate(posterior = (prior * likelihood) / (sum(prior * likelihood)))
# reshaping and plotting
g %>%
mutate(prior = prior/n,
likelihood = likelihood / sum(likelihood)) %>%
pivot_longer(cols = !p_grid) %>%
mutate(name = as_factor(name)) %>%
ggplot(aes(x = p_grid, ymin = 0, ymax = value, fill = name)) +
geom_ribbon() +
scale_fill_manual(values = wes_palette("Cavalcanti1")) +
theme(legend.position = "none") +
facet_wrap(~name)
# better than chance (approaches 0.5 as n --> infinity).
g %>%
filter(p_grid < 0.5) %>%
summarize(above = sum(posterior))
# quadratic
q <- quap(
alist(
c ~ dbinom(total, p),
p ~ dunif(0, 1)
),
data = list(
c = d$Correct[d$Teacher == "RF"],
total = d$Questions[d$Teacher == "RF"]
)
)
# check values
precis(q)
# plot stuff
n_grid <- 1000
# basic data frame
data <- tibble(p_grid = seq(from = 0,
to = 1,
length.out = n_grid),
prior = 1,
c = 3,
n = 6,
m = 0.5,
sd = 0.2) %>%
mutate(likelihood = dbinom(3, 6, p_grid),
grid_post = prior * likelihood / sum(prior * likelihood),
quad_post = dnorm(p_grid, m, sd) / sum(dnorm(p_grid, m, sd)))
# data wrangling & plotting
data %>%
pivot_longer(cols = grid_post:quad_post) %>%
mutate(name = as_factor(name)) %>%
ggplot(aes(x = p_grid, y = value, color = name)) +
geom_line()
# data wrangling & plotting
data %>%
pivot_longer(cols = grid_post:quad_post) %>%
mutate(approximation = as_factor(name)) %>%
ggplot(aes(x = p_grid, y = value, color = approximation)) +
geom_line()
# funcgion for computing posterior with grid.
grid_posterior <- function(data, n_grid, prior){
#empty placeholders
grid_teacher = tibble()
#main loop
for(i in data$Teacher){
g <- tibble(p_grid = seq(0, 1, length.out = n_grid),
prior = prior) %>%
mutate(likelihood = dbinom(x = data$Correct[data$Teacher == i],
size = data$Questions[data$Teacher == i],
p_grid)) %>%
mutate(posterior = (prior * likelihood) / (sum(prior * likelihood)),
Teacher = i)
grid_teacher = bind_rows(grid_teacher, g)
}
return(grid_teacher)
}
# the grid for Riccardo.
# this should be made smarter.
g <- tibble(p_grid = seq(0, 1, length.out = n),
prior = 1) %>%
mutate(likelihood = dbinom(x = d$Correct[d$Teacher == "RF"],
size = d$Questions[d$Teacher == "RF"],
p_grid)) %>%
mutate(posterior = (prior * likelihood) / (sum(prior * likelihood)))
g_test <- d %>%
group_by(Teacher) %>%
mutate(p_grid = seq(0, 1, length.out = n),
prior = 1)
g_test <- d %>%
group_by(Teacher) %>%
mutate(likelihood = dbinom(x = Correct,
size = Questions,
p_grid = seq(0, 1, length.out = n)))
g_test <- d %>%
group_by(Teacher) %>%
mutate(likelihood = dbinom(x = Correct,
size = Questions,
seq(0, 1, length.out = n)))
# check that the relative path works boys.
setwd("~/HCI/week1")
pacman::p_load(tidyverse, lmerTest, corrplot)
#Set your WD here:
df <- read.csv("clean_data.csv") %>%
as_tibble() %>%
glimpse()
df <- df %>%
mutate(website = as_factor(website),
event = as_factor(event),
name = as_factor(name),
order_tickets_online = as_factor(order_tickets_online),
session = as_factor(session),
cinemaxx_1st = as_factor(cinemaxx_1st)) %>%
glimpse()
# subset
df_cor <- df %>%
mutate(website_num = if_else(website == "cinemaxx", 0, 1)) %>%
select(!c(name, age, order_tickets_online,
website, event, session, cinemaxx_1st)) %>%
glimpse()
# correlation plot
M <- cor(df_cor)
corrplot(M, method = "square", type = "upper")
# preprocessing
df1 <- df %>%
mutate(event_re = forcats::fct_recode(event,
"0" = "fixation",
"1" = "saccade"),
event_num = as.numeric(event_re) - 1) %>%
group_by(session, website, name) %>%
mutate(n = row_number())
# more preprocessing
df2 <- df1 %>%
group_by(name, website,
grouping = with(rle(event_num) %>% set_names(c("lengths2", "values")),
rep(seq_along(lengths2), lengths2))) %>%
summarize(length = (max(n) - min(n) + 1),
type = max(event_num))
# last step
df3 <- df2 %>%
pivot_wider(names_from = type,
values_from = length) %>%
rename("fixation" = "0",
"saccade" = "1")
# more data wrangling needed.
fixation <- df3 %>%
filter(!is.na(fixation)) %>%
select(!saccade)
saccade <- df3 %>%
filter(!is.na(saccade)) %>%
mutate(grouping = grouping - 1) %>%
select(!fixation)
complete <- merge(fixation, saccade) %>%
mutate(website_num = as.numeric(forcats::fct_recode(
website,
"0" = "cinemaxx",
"1" = "nfbio")) - 1) %>%
glimpse()
# summary
d <- complete %>%
group_by(name, website_num) %>%
summarize(dur_fix_total = sum(fixation),
dur_sac_total = sum(saccade),
dur_total_frq = dur_fix_total/(dur_fix_total + dur_sac_total),
dur_fix_mean = mean(fixation),
dur_sac_mean = mean(saccade),
dur_mean_frq = dur_fix_mean/(dur_fix_mean+dur_sac_mean),
n_events = n()) %>%
glimpse()
# models with summary:
### number of fixations:
m_events <- lm(website_num ~ n_events,
data = d)
summary(m_events)
### fixation duration:
m_meanDur <- lm(website_num ~ dur_fix_mean + dur_sac_mean,
data = d)
summary(m_meanDur)
### fixation/saccade:
m_frq <- lm(website_num ~ dur_total_frq,
data = d)
summary(m_frq)
# scaling function (z)
scale_this <- function(x){
(x - mean(x, na.rm=TRUE)) / sd(x, na.rm=TRUE)
}
# mouse velocity
mouse <- df %>%
mutate(lag_x = lag(mouse_x),
lag_y = lag(mouse_y)) %>%
filter(!is.na(lag_x), !is.na(lag_y)) %>%
mutate(vel_x = abs(mouse_x - lag_x),
vel_y = abs(mouse_y - lag_y),
mouse_vel = sqrt(vel_x^2 + vel_y^2),
mouse_scaled = scale_this(mouse_vel),
eye_scaled = scale_this(velocity)) %>%
glimpse()
# plot mouse velocity
mouse %>%
ggplot() +
geom_density(aes(x = mouse_vel))
# with logistic
velocity_log <- glmer(website ~ mouse_scaled + eye_scaled + (1|name),
family = binomial, data = mouse)
summary(velocity_log) # more cinemaxx for both mouse and eye velocity.
# intercept on "natural" scale:
exp(0.056575)
# intercept on "natural" scale:
intercept = exp(0.056575)
exp(intercept - 0.024684)
exp(0.056575 - 0.024684)
fix = ggplot(df %>% filter(event == "fixation"), aes(x, y, color = website)) +
geom_point(alpha = 0.01) +
geom_density2d() +
labs(title = "Fixations")
mouse = ggplot(df, aes(mouse_x, mouse_y, color = website)) +
geom_point(alpha = 0.01) +
geom_density2d() +
labs(title = "Mouse position")
pacman::p_load(cowplot)
plot_grid(fix, mouse, nrow = 2)
